{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Install Required Packages_\n",
    "\n",
    "use brew for easy installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```brew install rust sentencepiece```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"pythainlp[full]\"\n",
    "%pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Word tokenization and tagging_\n",
    "\n",
    "**Important**: must run on x86 or x86_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['สามารถ', 'ดู', 'รายนาม', 'อธิบดี', 'กรมทรัพย์สินทางปัญญา', 'ตั้งแต่', 'อดีต', 'ได้', 'ที่ไหน']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/autobot/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 883k/883k [00:26<00:00, 34.2kB/s] \n",
      "Downloading: 100%|██████████| 282/282 [00:00<00:00, 101kB/s]\n",
      "Downloading: 100%|██████████| 546/546 [00:00<00:00, 172kB/s]\n",
      "Downloading: 100%|██████████| 1.03k/1.03k [00:00<00:00, 244kB/s]\n",
      "2022-07-12 09:16:59.228335: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-12 09:16:59.228993: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type camembert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model airesearch/wangchanberta-base-att-spm-uncased with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForTokenClassification'>, <class 'transformers.models.roberta.modeling_tf_roberta.TFRobertaForTokenClassification'>).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/setta/Documents/Working/convergence/autobot/autobot/notebooks/thainlp.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/setta/Documents/Working/convergence/autobot/autobot/notebooks/thainlp.ipynb#ch0000000?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(tokens)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/setta/Documents/Working/convergence/autobot/autobot/notebooks/thainlp.ipynb#ch0000000?line=9'>10</a>\u001b[0m \u001b[39m# Thai name tagger\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/setta/Documents/Working/convergence/autobot/autobot/notebooks/thainlp.ipynb#ch0000000?line=11'>12</a>\u001b[0m ner \u001b[39m=\u001b[39m NER(\u001b[39m\"\u001b[39;49m\u001b[39mwangchanberta\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/setta/Documents/Working/convergence/autobot/autobot/notebooks/thainlp.ipynb#ch0000000?line=12'>13</a>\u001b[0m ner\u001b[39m.\u001b[39mtag(sentence)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/autobot/lib/python3.9/site-packages/pythainlp/tag/named_entity.py:28\u001b[0m, in \u001b[0;36mNER.__init__\u001b[0;34m(self, engine, corpus)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, engine: \u001b[39mstr\u001b[39m, corpus: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mthainer\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_engine(engine\u001b[39m=\u001b[39;49mengine, corpus\u001b[39m=\u001b[39;49mcorpus)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/autobot/lib/python3.9/site-packages/pythainlp/tag/named_entity.py:37\u001b[0m, in \u001b[0;36mNER.load_engine\u001b[0;34m(self, engine, corpus)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m ThaiNameTagger()\n\u001b[1;32m     36\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwangchanberta\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpythainlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwangchanberta\u001b[39;00m \u001b[39mimport\u001b[39;00m ThaiNameTagger\n\u001b[1;32m     38\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m ThaiNameTagger(dataset_name\u001b[39m=\u001b[39mcorpus)\n\u001b[1;32m     39\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtltk\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/autobot/lib/python3.9/site-packages/pythainlp/wangchanberta/__init__.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThaiNameTagger\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpos_tag\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msegment\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpythainlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwangchanberta\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m ThaiNameTagger, segment\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpythainlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwangchanberta\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpostag\u001b[39;00m \u001b[39mimport\u001b[39;00m pos_tag\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/autobot/lib/python3.9/site-packages/pythainlp/wangchanberta/postag.py:69\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m _corpus \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlst20\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m _grouped_word \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m _postag \u001b[39m=\u001b[39m PosTagTransformers(corpus\u001b[39m=\u001b[39;49m_corpus, grouped_word\u001b[39m=\u001b[39;49m_grouped_word)\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpos_tag\u001b[39m(\n\u001b[1;32m     73\u001b[0m     text: \u001b[39mstr\u001b[39m, corpus: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlst20\u001b[39m\u001b[39m\"\u001b[39m, grouped_word: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     74\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m     75\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m    Marks words with part-of-speech (POS) tags.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m    :rtype: list[tuple[str, str]]\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/autobot/lib/python3.9/site-packages/pythainlp/wangchanberta/postag.py:26\u001b[0m, in \u001b[0;36mPosTagTransformers.__init__\u001b[0;34m(self, corpus, grouped_word)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus \u001b[39m=\u001b[39m corpus\n\u001b[1;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouped_word \u001b[39m=\u001b[39m grouped_word\n\u001b[0;32m---> 26\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/autobot/lib/python3.9/site-packages/pythainlp/wangchanberta/postag.py:29\u001b[0m, in \u001b[0;36mPosTagTransformers.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassify_tokens \u001b[39m=\u001b[39m pipeline(\n\u001b[1;32m     30\u001b[0m         task\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mner\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     31\u001b[0m         tokenizer\u001b[39m=\u001b[39;49m_tokenizer,\n\u001b[1;32m     32\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mairesearch/\u001b[39;49m\u001b[39m{\u001b[39;49;00m_model_name\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     33\u001b[0m         revision\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfinetuned@\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus\u001b[39m}\u001b[39;49;00m\u001b[39m-pos\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     34\u001b[0m         ignore_labels\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m     35\u001b[0m         grouped_entities\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouped_word\n\u001b[1;32m     36\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/autobot/lib/python3.9/site-packages/transformers/pipelines/__init__.py:567\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Infer the framework from the model\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39m# Will load the correct model if possible\u001b[39;00m\n\u001b[1;32m    566\u001b[0m model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> 567\u001b[0m framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    568\u001b[0m     model,\n\u001b[1;32m    569\u001b[0m     model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[1;32m    570\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    571\u001b[0m     framework\u001b[39m=\u001b[39;49mframework,\n\u001b[1;32m    572\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    573\u001b[0m     task\u001b[39m=\u001b[39;49mtask,\n\u001b[1;32m    574\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    575\u001b[0m )\n\u001b[1;32m    577\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    579\u001b[0m load_tokenizer \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(model_config) \u001b[39min\u001b[39;00m TOKENIZER_MAPPING \u001b[39mor\u001b[39;00m model_config\u001b[39m.\u001b[39mtokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/autobot/lib/python3.9/site-packages/transformers/pipelines/base.py:265\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 265\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load model \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m with any of the following classes: \u001b[39m\u001b[39m{\u001b[39;00mclass_tuple\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m framework \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mTF\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[39mreturn\u001b[39;00m framework, model\n",
      "\u001b[0;31mValueError\u001b[0m: Could not load model airesearch/wangchanberta-base-att-spm-uncased with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForTokenClassification'>, <class 'transformers.models.roberta.modeling_tf_roberta.TFRobertaForTokenClassification'>)."
     ]
    }
   ],
   "source": [
    "from pythainlp import word_tokenize\n",
    "from pythainlp.tag import pos_tag, pos_tag_sents\n",
    "from pythainlp.tag.named_entity import NER\n",
    "\n",
    "sentence = [\n",
    "    'สามารถดูรายนามอธิบดีกรมทรัพย์สินทางปัญญาตั้งแต่อดีตได้ที่ไหน', \n",
    "    'ผมมีชื่อว่า นายวรรณพงษ์ ภัททิยไพบูลย์'\n",
    "    ]\n",
    "tokens = word_tokenize(sentence, keep_whitespace=False)\n",
    "tags = pos_tag_sents(tokens)\n",
    "print(tokens)\n",
    "\n",
    "# Thai name tagger\n",
    "\n",
    "ner = NER(\"wangchanberta\")\n",
    "ner.tag(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('autobot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc1ae1c4a63fb27a31f43134f4e5db0402df2726bb103cc85ed273abf3107fe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
